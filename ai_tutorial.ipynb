{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Policymaking : a decision-making problem about CO2 mitigation\n",
    "\n",
    "dapted from EMA Workbench Lakeproblem Example\n",
    "\n",
    "The Climate Change Problem forms a hypothetical scenario where the global community makes the decision on the amount of annual CO2 emissions to be released. The challenge is, if the CO2 concentration in the atmosphere surpasses a certain critical threshold or a \"tipping point\", it may cause irreversible and dangerous changes to the global climate system.\n",
    "\n",
    "The Climate Change model has 4 **outcome indicators**:\n",
    "\n",
    "1. **CO2_concentration**: The average concentration of CO2 in the atmosphere over a given timeframe, which we aim to minimize.\n",
    "\n",
    "2. **economic_welfare**: The economic benefits derived from emitting CO2 minus the costs of having excessive CO2 in the atmosphere, which we aim to maximize.\n",
    "\n",
    "3. **emission_inertia**: Inertia is maximized by setting an annual reduction limit on emissions, thereby preventing rapid declines in emissions that would require massive investments, and measured by the fraction of years where emission reductions stay below the set limit.\n",
    "\n",
    "4. **reliability**: The fraction of years when the CO2 concentration in the atmosphere is below the critical threshold, which we aim to maximize to prevent triggering dangerous climate disruptions.\n",
    "\n",
    "The Climate Change Problem is characterized by both stochastic uncertainty and **deep uncertainty**. The stochastic uncertainty arises from the natural emissions of CO2. In order to reduce this form of uncertainty, multiple replications are performed, and the average over these replications is taken. Deep uncertainty involves uncertainty about the mean and standard deviation of the log-normal distribution representing natural emissions, Earth's natural CO2 absorption rate, the natural emission rate of CO2, and the discount rate. Based on scientific understanding, ranges for these deeply uncertain factors can be established, as well as their best estimate or default values.\n",
    "\n",
    "|Parameter\t|Range\t        |Default value| Description |\n",
    "|-----------|--------------:|------------:|---------------------------:|\n",
    "|$\\mu$    \t|0.01 – 0.05\t|0.02         | Mean of the log-normal distribution representing the natural variability in CO2 emissions |\n",
    "|$\\sigma$\t|0.001 – 0.005 \t|0.0017       | Standard deviation of the log-normal distribution representing the natural variability in CO2 emissions |\n",
    "|$b$      \t|0.1 – 0.45\t    |0.42         | Earth’s natural CO2 absorption rate, representing the rate at which CO2 is removed from the atmosphere |\n",
    "|$q$\t    |2 – 4.5\t    |2            | Represents a decay rate in the concentration of CO2 in the atmosphere due to oceanic absorption |\n",
    "|$\\delta$\t|0.93 – 0.99\t|0.98         | Discount rate for the economic welfare calculation, indicating the decrease in future benefits compared to present benefits |\n",
    "\n",
    "we apply a more sophisticated strategy to the problem of climate change. We employ a **closed-loop** version of the model, which means that anthropogenic emissions, represented as $a_t$, is dependent on $X_t$ (the CO2 concentration in the atmosphere at time t). For instance, we can lowerCO2 emissions when approaching the critical threshold. Using \"cubic radial basis functions\", following Quinn et al. 2017 we formulate $a_t$ as follows: (Please note that the formulation of $a_t$ will depend on the policy and decision mechanisms introduced, which could include a range of tools from emission tax, cap-and-trade schemes to regulations).\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    a_{t} =  min\\Bigg(max\\bigg(\\sum\\limits_{j=1}^{n} w_{j}\\left\\vert{\\frac{X_{t,i}-c_{j}}{r_{j}}}\\right\\vert^3, 0.01\\bigg), 0.1\\Bigg) \\\\\n",
    "    s.t. \\\\\n",
    "    -2 \\leq c_{j} \\leq 2 \\\\\n",
    "    0 \\leq r_{j} \\leq 2 \\\\ \n",
    "    0 \\leq w_{j} \\leq 1 \\\\\n",
    "    \\sum\\limits_{j=1}^{n} w_{j} = 1\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The parameters that define this function also define the emissions strategy over time. Hence, the decision **levers** are the five parameters of this functions, namely $c_1$, $c_2$, $r_1$, $r_2$ and $w_1$. ($w_2$ = 1 - $w_1$).\n",
    "\n",
    "Note:: i is index for the realization, given m realizations; j is the index for the radial basis function, given 2 radial basis functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required packages\n",
    "\n",
    "from ema_workbench import RealParameter, ScalarOutcome, Constant, Model\n",
    "#from optimization_lake_model_dps import lake_problem\n",
    "from model.simple_climate_economy_model import climate_policy_model\n",
    "from ema_workbench import MultiprocessingEvaluator, ema_logging, perform_experiments\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "from ema_workbench.analysis import pairs_plotting\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model in XLRM framework for  Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the XLRM framework to set up the exploration of the model\n",
    "\n",
    "model = Model(\"climatepolicymodel\", function=climate_policy_model)\n",
    "\n",
    "# specify uncertainties\n",
    "model.uncertainties = [\n",
    "    RealParameter(\"b\", 0.1, 0.45),\n",
    "    RealParameter(\"q\", 2.0, 4.5),\n",
    "    RealParameter(\"mean\", 0.01, 0.05),\n",
    "    RealParameter(\"stdev\", 0.001, 0.005),\n",
    "    RealParameter(\"delta\", 0.93, 0.99),\n",
    "]\n",
    "\n",
    "# set levers\n",
    "model.levers = [\n",
    "    RealParameter(\"c1\", -2, 2),\n",
    "    RealParameter(\"c2\", -2, 2),\n",
    "    RealParameter(\"r1\", 0, 2),\n",
    "    RealParameter(\"r2\", 0, 2),\n",
    "    RealParameter(\"w1\", 0, 1),\n",
    "]\n",
    "\n",
    "# specify outcomes\n",
    "model.outcomes = [\n",
    "    ScalarOutcome(\"max_CO2\"),\n",
    "    ScalarOutcome(\"economic_welfare\"),\n",
    "    ScalarOutcome(\"emission_inertia\"),\n",
    "    ScalarOutcome(\"reliability\"),\n",
    "]\n",
    "\n",
    "#TODO remove this later\n",
    "# override some of the defaults of the model\n",
    "model.constants = [\n",
    "    Constant(\"alpha\", 0.41),\n",
    "    Constant(\"nsamples\", 150),\n",
    "    Constant(\"myears\", 100),\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    # Run 1000 scenarios for 10 policies\n",
    "    #Can play around with number of Scenarios and Policies\n",
    "    #Note: Large numbers of scenarios and policies will take a long time to run\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios=1000, policies=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the different possible outcomes arising from combinations of the decision levers and uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = pairs_plotting.pairs_scatter(experiments, outcomes, group_by=\"policy\", legend=False)\n",
    "fig.set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for Pareto optimal solutions using MOEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_resolution = 0.1\n",
    "\n",
    "# specify outcomes\n",
    "model.outcomes = [\n",
    "    ScalarOutcome(\"max_CO2\", ScalarOutcome.MINIMIZE),\n",
    "    ScalarOutcome(\"economic_welfare\", ScalarOutcome.MAXIMIZE),\n",
    "    ScalarOutcome(\"emission_inertia\", ScalarOutcome.MAXIMIZE),\n",
    "    ScalarOutcome(\"reliability\", ScalarOutcome.MAXIMIZE),\n",
    "]\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    results = evaluator.optimize(nfe=5e3, searchover='levers',\n",
    "                                 epsilons=[search_resolution,]*len(model.outcomes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the trade-offs between the different objectives in Parallel Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = results.loc[:, [o.name for o in model.outcomes]]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['economic_welfare', 'emission_inertia', 'reliability', 'max_CO2']] = 0\n",
    "\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits, rot = 45)\n",
    "paraxes.plot(data)\n",
    "paraxes.invert_axis('max_CO2')\n",
    "\n",
    "\n",
    "# Change the size of the plot\n",
    "paraxes.fig.set_size_inches(20, 14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 3: Select candidate solutions under uncertainty\n",
    "\n",
    "We now have a large number of candidate solutions (policies), we can re-evaluate them over the various deeply uncertain factors to assess their robustness against uncertainties.\n",
    "\n",
    "For this robustness evaluation, we need to explore the scenarios for each solution. It means that, if we would like to run for instance 1000 scenarios for each solution, we might have to execute a very large number of runs.\n",
    "\n",
    "Here, to simplify the case, let's suppose that decision makers have a hard constrain on *reliability*. No solution with less than 90% reliability is acceptable for them. Therefore, we can reduce the size of the solution set according to this constraint. \n",
    "\n",
    "**Apply this constraint of reliability on the results, and create a new dataframe named new_reults**\n",
    "\n",
    "\n",
    "There are various ways to do it. One way is to use logical indexing. Basically, create a boolean vector that indicates for each row if the constraint is met or not. Next, we can use this as an index on the dataframe to get only the rows for which the index is true.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the policies based on specific criteria\n",
    "\n",
    "logical = (results.reliability > 0.6 ) & (results.max_CO2 < 0.2) & (results.economic_welfare > 0.4)\n",
    "np.sum(logical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = results[logical]\n",
    "data = data.loc[:, [o.name for o in model.outcomes]]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['economic_welfare', 'emission_inertia', 'reliability', 'max_CO2']] = 0\n",
    "\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits, rot = 45)\n",
    "paraxes.plot(data)\n",
    "paraxes.invert_axis('max_CO2')\n",
    "\n",
    "\n",
    "# Change the size of the plot\n",
    "paraxes.fig.set_size_inches(20, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[logical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = results[logical]\n",
    "policies = policies.drop([o.name for o in model.outcomes], axis=1)\n",
    "policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
